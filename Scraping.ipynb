{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping : Extracting books information\n",
    "\n",
    "This notebook extract information from http://books.toscrape.com.\n",
    "\n",
    "It uses **httpx** to perform asynchronous request on shop and book page\n",
    "\n",
    "**BeautifulSoup** is later used to parse the html responses.\n",
    "\n",
    "Extracted information are then saved in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.python-httpx.org/\n",
    "# !pip install httpx\n",
    "# https://beautiful-soup-4.readthedocs.io/en/latest/#\n",
    "# !pip install beautifulsoup4\n",
    "# https://github.com/alexmojaki/sorcery\n",
    "# !pip install sorcery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import asyncio\n",
    "from sorcery import dict_of\n",
    "import pandas as pd\n",
    "\n",
    "# optional\n",
    "from rich import print\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> requests completed. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> failures\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m50\u001b[0m requests completed. \u001b[1;36m0\u001b[0m failures\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = 'http://books.toscrape.com/catalogue/'\n",
    "base_url = 'http://books.toscrape.com/catalogue/page-{}.html'\n",
    "shop_link = [base_url.format(i) for i in range(1,51)]\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    tasks = [client.get(url) for url in shop_link]\n",
    "    reqs = await asyncio.gather(*tasks)\n",
    " \n",
    "# Checking reqs status\n",
    "failed = len([r for r in reqs if r.status_code != 200])\n",
    "print(f'{len(reqs)} requests completed. {failed} failures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total book links extracted: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total book links extracted: \u001b[1;36m1000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soups = [BeautifulSoup(r.text, 'html.parser') for r in reqs]\n",
    "# Extracting links of book \n",
    "books_link = []\n",
    "\n",
    "for i, soup in enumerate(soups):\n",
    "    books_tag = soup.select('div.image_container > a')\n",
    "    for book_tag in books_tag:\n",
    "        books_link.append(root + str(book_tag['href']))\n",
    "    # print(f'Extracted {len(books_tag)} books links from {shop_link[i]}')\n",
    "    \n",
    "print(f'Total book links extracted: {len(books_link)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span> requests completed. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> failures\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1000\u001b[0m requests completed. \u001b[1;36m0\u001b[0m failures\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting book page\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    tasks = [client.get(url) for url in books_link]\n",
    "    reqs = await asyncio.gather(*tasks)\n",
    "    \n",
    "# Checking reqs status   \n",
    "failed = len([r for r in reqs if r.status_code != 200])\n",
    "print(f'{len(reqs)} requests completed. {failed} failures')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting books information\n",
    "\n",
    "- Title - as primary key\n",
    "- Book genre\n",
    "- Book description\n",
    "- Price\n",
    "- Stock\n",
    "- Rating\n",
    "- Book cover url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Total book information extracted: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Total book information extracted: \u001b[1;36m1000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soups = [BeautifulSoup(r.text, 'html.parser') for r in reqs]\n",
    "books = dict()\n",
    "\n",
    "def extract_book_info(soup):\n",
    "    title = soup.select('div.product_main > h1')[0].text\n",
    "    category = soup.select('ul.breadcrumb > li:nth-child(3) > a')[0].text\n",
    "    if soup.select('article.product_page > p'):\n",
    "        description = soup.select('article.product_page > p')[0].text\n",
    "    else : \n",
    "        description = None\n",
    "    price = soup.select('div.product_main > p.price_color')[0].text\n",
    "    stock = soup.select('div.product_main > p.instock.availability')[0].text\n",
    "    url = books_link[i]\n",
    "    # Could be handled better but this 🤷‍♀️ work :  \n",
    "    cover_url = 'http://books.toscrape.com/' + soup.select('div.thumbnail > div > div > img')[0]['src'][6:]\n",
    "    \n",
    "    rating = soup.select('p.star-rating')[0]['class'][1]\n",
    "    rating_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    rating = rating_dict.get(rating, None)\n",
    "    \n",
    "    \n",
    "    # Search digits in stock\n",
    "    stock = re.search(r'\\d+', stock)\n",
    "    if stock:\n",
    "        stock = int(stock.group(0))\n",
    "    else: \n",
    "        stock = 0\n",
    "    \n",
    "    book = dict_of(category, rating, description, price, stock, url, cover_url)\n",
    "    \n",
    "    books[title] = book\n",
    "    pass\n",
    "\n",
    "soups = [BeautifulSoup(r.text, 'html.parser') for r in reqs]\n",
    "for soup in soups:\n",
    "    extract_book_info(soup)\n",
    "    \n",
    "print(f'Total book information extracted: {len(books_link)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>stock</th>\n",
       "      <th>url</th>\n",
       "      <th>cover_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Avatar: The Last Airbender: Smoke and Shadow, ...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2</td>\n",
       "      <td>Children are disappearing in the Fire Nation c...</td>\n",
       "      <td>£28.09</td>\n",
       "      <td>16</td>\n",
       "      <td>http://books.toscrape.com/catalogue/unicorn-tr...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/9f/25/9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>Fruits Basket, Vol. 1 (Fruits Basket #1)</td>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>5</td>\n",
       "      <td>A family with an ancient curse...And the girl ...</td>\n",
       "      <td>£40.28</td>\n",
       "      <td>1</td>\n",
       "      <td>http://books.toscrape.com/catalogue/unicorn-tr...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/03/c5/03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>The Demon Prince of Momochi House, Vol. 4 (The...</td>\n",
       "      <td>Sequential Art</td>\n",
       "      <td>2</td>\n",
       "      <td>On her sixteenth birthday, orphan Himari Momoc...</td>\n",
       "      <td>£27.88</td>\n",
       "      <td>4</td>\n",
       "      <td>http://books.toscrape.com/catalogue/unicorn-tr...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/20/99/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Slow States of Collapse: Poems</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>3</td>\n",
       "      <td>The eagerly anticipated debut from one of Cana...</td>\n",
       "      <td>£57.31</td>\n",
       "      <td>17</td>\n",
       "      <td>http://books.toscrape.com/catalogue/unicorn-tr...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/db/ac/db...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Night (The Night Trilogy #1)</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>1</td>\n",
       "      <td>Night is a work by Elie Wiesel about his exper...</td>\n",
       "      <td>£13.51</td>\n",
       "      <td>3</td>\n",
       "      <td>http://books.toscrape.com/catalogue/unicorn-tr...</td>\n",
       "      <td>http://books.toscrape.com/media/cache/b2/45/b2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title        category rating  \\\n",
       "119  Avatar: The Last Airbender: Smoke and Shadow, ...         Fantasy      2   \n",
       "978           Fruits Basket, Vol. 1 (Fruits Basket #1)  Sequential Art      5   \n",
       "655  The Demon Prince of Momochi House, Vol. 4 (The...  Sequential Art      2   \n",
       "40                      Slow States of Collapse: Poems          Poetry      3   \n",
       "800                       Night (The Night Trilogy #1)      Nonfiction      1   \n",
       "\n",
       "                                           description   price stock  \\\n",
       "119  Children are disappearing in the Fire Nation c...  £28.09    16   \n",
       "978  A family with an ancient curse...And the girl ...  £40.28     1   \n",
       "655  On her sixteenth birthday, orphan Himari Momoc...  £27.88     4   \n",
       "40   The eagerly anticipated debut from one of Cana...  £57.31    17   \n",
       "800  Night is a work by Elie Wiesel about his exper...  £13.51     3   \n",
       "\n",
       "                                                   url  \\\n",
       "119  http://books.toscrape.com/catalogue/unicorn-tr...   \n",
       "978  http://books.toscrape.com/catalogue/unicorn-tr...   \n",
       "655  http://books.toscrape.com/catalogue/unicorn-tr...   \n",
       "40   http://books.toscrape.com/catalogue/unicorn-tr...   \n",
       "800  http://books.toscrape.com/catalogue/unicorn-tr...   \n",
       "\n",
       "                                             cover_url  \n",
       "119  http://books.toscrape.com/media/cache/9f/25/9f...  \n",
       "978  http://books.toscrape.com/media/cache/03/c5/03...  \n",
       "655  http://books.toscrape.com/media/cache/20/99/20...  \n",
       "40   http://books.toscrape.com/media/cache/db/ac/db...  \n",
       "800  http://books.toscrape.com/media/cache/b2/45/b2...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some random samples of books extracted\n",
    "df = pd.DataFrame(books).T\n",
    "df = df.reset_index(names = 'title')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to csv\n",
    "df.to_csv('books.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3_10_for_DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
